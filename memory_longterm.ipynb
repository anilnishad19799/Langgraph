{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d48ef8-fc2e-4576-b7bf-8b8dfc15984d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.chat_models import init_chat_model\n",
    "from dataclasses import dataclass\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0a5a778-6bb7-46f6-ac13-54b9d1e3ad85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langgraph.graph import StateGraph, MessagesState, START\n",
    "from langgraph.checkpoint.postgres import PostgresSaver\n",
    "from langgraph.store.postgres import PostgresStore\n",
    "from langgraph.store.base import BaseStore\n",
    "import uuid\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7e2c3e2-f39a-4871-a092-907a2b893a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_URI = \"postgresql://postgres:postgres@localhost:5432/postgres?sslmode=disable\"\n",
    "model = init_chat_model(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0685550-4819-45fc-85bf-e457f669b892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "My name is Anthony\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Thanks for letting me know, Anthony! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with (\n",
    "    PostgresStore.from_conn_string(DB_URI) as store,\n",
    "    PostgresSaver.from_conn_string(DB_URI) as checkpointer,\n",
    "):\n",
    "    store.setup()\n",
    "    checkpointer.setup()\n",
    "\n",
    "    def call_model(\n",
    "        state: MessagesState,\n",
    "        config: RunnableConfig,\n",
    "        *,\n",
    "        store: BaseStore,\n",
    "    ):\n",
    "        user_id = config[\"configurable\"][\"user_id\"]\n",
    "        namespace = (\"memories\", user_id)\n",
    "        memories = store.search(namespace, query=str(state[\"messages\"][-1].content))\n",
    "        info = \"\\n\".join([d.value[\"data\"] for d in memories])\n",
    "        system_msg = f\"You are a helpful assistant talking to the user. User info: {info}\"\n",
    "\n",
    "        # Store new memories if the user asks the model to remember\n",
    "        last_message = state[\"messages\"][-1]\n",
    "        if \"remember\" in last_message.content.lower():\n",
    "            memory = \"User name is Bob\"\n",
    "            store.put(namespace, str(uuid.uuid4()), {\"data\": memory})\n",
    "\n",
    "        response = model.invoke(\n",
    "            [{\"role\": \"system\", \"content\": system_msg}] + state[\"messages\"]\n",
    "        )\n",
    "        return {\"messages\": response}\n",
    "\n",
    "\n",
    "    builder = StateGraph(MessagesState)\n",
    "    builder.add_node(\"call_model\", call_model)\n",
    "    builder.add_edge(START, \"call_model\")\n",
    " \n",
    "\n",
    "    graph = builder.compile(\n",
    "        checkpointer=checkpointer,\n",
    "        store=store,\n",
    "    )\n",
    "\n",
    "    user_id_name=\"steve rogers\"\n",
    "    config = {\n",
    "        \"configurable\": {\n",
    "            \"thread_id\": \"1\",\n",
    "            \"user_id\": user_id_name,\n",
    "        }\n",
    "    }\n",
    "    for chunk in graph.stream(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": \"My name is Anthony\"}]},\n",
    "        config,\n",
    "        stream_mode=\"values\",\n",
    "    ):\n",
    "        chunk[\"messages\"][-1].pretty_print()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9943d1c9-9b52-4316-9158-2923961a13d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Please comment on my food choice\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "From what you've shared, it seems you enjoy bold flavors with your preference for butter naan with chili flakes, while lasagna isn't to your taste. This suggests you might prefer dishes that have a balance of rich and spicy elements. It's always great to explore and enjoy foods that align with your taste preferences. Trying new combinations or cuisines can also be a fun way to expand your palate. If you have any other food interests or are looking for recommendations, feel free to share!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with (\n",
    "    PostgresStore.from_conn_string(DB_URI) as store,\n",
    "    PostgresSaver.from_conn_string(DB_URI) as checkpointer,\n",
    "):\n",
    "    # store.setup()\n",
    "    # checkpointer.setup()\n",
    "\n",
    "    def call_model(\n",
    "        state: MessagesState,\n",
    "        config: RunnableConfig,\n",
    "        *,\n",
    "        store: BaseStore,\n",
    "    ):\n",
    "        user_id = config[\"configurable\"][\"user_id\"]\n",
    "        namespace = (\"memories\", user_id)\n",
    "        memories = store.search(namespace, query=str(state[\"messages\"][-1].content))\n",
    "        info = \"\\n\".join([d.value[\"data\"] for d in memories])\n",
    "        system_msg = f\"You are a helpful assistant talking to the user. User info: {info}\"\n",
    "\n",
    "        # Store new memories if the user asks the model to remember\n",
    "        last_message = state[\"messages\"][-1]\n",
    "        if \"remember\" in last_message.content.lower():\n",
    "            memory = \"User name is Bob\"\n",
    "            store.put(namespace, str(uuid.uuid4()), {\"data\": memory})\n",
    "\n",
    "        response = model.invoke(\n",
    "            [{\"role\": \"system\", \"content\": system_msg}] + state[\"messages\"]\n",
    "        )\n",
    "        return {\"messages\": response}\n",
    "\n",
    "\n",
    "    builder = StateGraph(MessagesState)\n",
    "    builder.add_node(\"call_model\", call_model)\n",
    "    builder.add_edge(START, \"call_model\")\n",
    " \n",
    "\n",
    "    graph = builder.compile(\n",
    "        checkpointer=checkpointer,\n",
    "        store=store,\n",
    "    )\n",
    "\n",
    "    user_id_name=\"steve rogers\"\n",
    "    config = {\n",
    "        \"configurable\": {\n",
    "            \"thread_id\": \"1\",\n",
    "            \"user_id\": user_id_name,\n",
    "        }\n",
    "    }\n",
    "    for chunk in graph.stream(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": \"Please comment on my food choice\"}]},\n",
    "        config,\n",
    "        stream_mode=\"values\",\n",
    "    ):\n",
    "        chunk[\"messages\"][-1].pretty_print()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4afe31-c761-4d24-bc4b-044b1d1a8971",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb216e6-744b-4d95-90c4-1382b5f3e458",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "120a7477-9306-4546-9dff-693401d2894c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "My name is Leonidis\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Thank you for the reminder, Leonidis! If there's anything else you'd like to talk about or if you have any questions, feel free to let me know.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with (\n",
    "    PostgresStore.from_conn_string(DB_URI) as store,\n",
    "    PostgresSaver.from_conn_string(DB_URI) as checkpointer,\n",
    "):\n",
    "    # store.setup()\n",
    "    # checkpointer.setup()\n",
    "\n",
    "    def call_model(\n",
    "        state: MessagesState,\n",
    "        config: RunnableConfig,\n",
    "        *,\n",
    "        store: BaseStore,\n",
    "    ):\n",
    "        user_id = config[\"configurable\"][\"user_id\"]\n",
    "        namespace = (\"memories\", user_id)\n",
    "        memories = store.search(namespace, query=str(state[\"messages\"][-1].content))\n",
    "        info = \"\\n\".join([d.value[\"data\"] for d in memories])\n",
    "        system_msg = f\"You are a helpful assistant talking to the user. User info: {info}\"\n",
    "\n",
    "        # Store new memories if the user asks the model to remember\n",
    "        last_message = state[\"messages\"][-1]\n",
    "        if \"remember\" in last_message.content.lower():\n",
    "            memory = \"User name is Bob\"\n",
    "            store.put(namespace, str(uuid.uuid4()), {\"data\": memory})\n",
    "\n",
    "        response = model.invoke(\n",
    "            [{\"role\": \"system\", \"content\": system_msg}] + state[\"messages\"]\n",
    "        )\n",
    "        return {\"messages\": response}\n",
    "\n",
    "\n",
    "    builder = StateGraph(MessagesState)\n",
    "    builder.add_node(\"call_model\", call_model)\n",
    "    builder.add_edge(START, \"call_model\")\n",
    " \n",
    "\n",
    "    graph = builder.compile(\n",
    "        checkpointer=checkpointer,\n",
    "        store=store,\n",
    "    )\n",
    "\n",
    "    user_id_name=\"shaktimaan\"\n",
    "    config = {\n",
    "        \"configurable\": {\n",
    "            \"thread_id\": \"2\",\n",
    "            \"user_id\": user_id_name,\n",
    "        }\n",
    "    }\n",
    "    for chunk in graph.stream(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": \"My name is Leonidis\"}]},\n",
    "        config,\n",
    "        stream_mode=\"values\",\n",
    "    ):\n",
    "        chunk[\"messages\"][-1].pretty_print()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49852d2-f717-47ea-91b0-c46d7454308a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef7319b8-edb4-4a78-af2f-fbcbf52d5768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Remember: I am Thorin\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Got it, Thorin! If there's anything else you'd like to add or discuss, just let me know!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with (\n",
    "    PostgresStore.from_conn_string(DB_URI) as store,\n",
    "    PostgresSaver.from_conn_string(DB_URI) as checkpointer,\n",
    "):\n",
    "    # store.setup()\n",
    "    # checkpointer.setup()\n",
    "\n",
    "    def call_model(\n",
    "        state: MessagesState,\n",
    "        config: RunnableConfig,\n",
    "        *,\n",
    "        store: BaseStore,\n",
    "    ):\n",
    "        user_id = config[\"configurable\"][\"user_id\"]\n",
    "        namespace = (\"memories\", user_id)\n",
    "        memories = store.search(namespace, query=str(state[\"messages\"][-1].content))\n",
    "        info = \"\\n\".join([d.value[\"data\"] for d in memories])\n",
    "        system_msg = f\"You are a helpful assistant talking to the user. User info: {info}\"\n",
    "\n",
    "        # Store new memories if the user asks the model to remember\n",
    "        last_message = state[\"messages\"][-1]\n",
    "        if \"remember\" in last_message.content.lower():\n",
    "            memory = \"User name is Bob\"\n",
    "            store.put(namespace, str(uuid.uuid4()), {\"data\": memory})\n",
    "\n",
    "        response = model.invoke(\n",
    "            [{\"role\": \"system\", \"content\": system_msg}] + state[\"messages\"]\n",
    "        )\n",
    "        return {\"messages\": response}\n",
    "\n",
    "\n",
    "    builder = StateGraph(MessagesState)\n",
    "    builder.add_node(\"call_model\", call_model)\n",
    "    builder.add_edge(START, \"call_model\")\n",
    " \n",
    "\n",
    "    graph = builder.compile(\n",
    "        checkpointer=checkpointer,\n",
    "        store=store,\n",
    "    )\n",
    "\n",
    "    user_id_name=\"shaktimaan\"\n",
    "    config = {\n",
    "        \"configurable\": {\n",
    "            \"thread_id\": \"2\",\n",
    "            \"user_id\": user_id_name,\n",
    "        }\n",
    "    }\n",
    "    for chunk in graph.stream(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": \"Remember: I am Thorin\"}]},\n",
    "        config,\n",
    "        stream_mode=\"values\",\n",
    "    ):\n",
    "        chunk[\"messages\"][-1].pretty_print()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7050a6a2-6c30-49cd-a852-a89d716a7b42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "040dc512-587b-47cc-bc21-04add89f6f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "remember: I like Batman not much of superman\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Got it! You prefer Batman over Superman. Let me know if there's anything else you'd like to add or discuss!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with (\n",
    "    PostgresStore.from_conn_string(DB_URI) as store,\n",
    "    PostgresSaver.from_conn_string(DB_URI) as checkpointer,\n",
    "):\n",
    "    # store.setup()\n",
    "    # checkpointer.setup()\n",
    "\n",
    "    def call_model(\n",
    "        state: MessagesState,\n",
    "        config: RunnableConfig,\n",
    "        *,\n",
    "        store: BaseStore,\n",
    "    ):\n",
    "        user_id = config[\"configurable\"][\"user_id\"]\n",
    "        namespace = (\"memories\", user_id)\n",
    "        memories = store.search(namespace, query=str(state[\"messages\"][-1].content))\n",
    "        info = \"\\n\".join([d.value[\"data\"] for d in memories])\n",
    "        system_msg = f\"You are a helpful assistant talking to the user. User info: {info}\"\n",
    "\n",
    "        # Store new memories if the user asks the model to remember\n",
    "        last_message = state[\"messages\"][-1]\n",
    "        if \"remember\" in last_message.content.lower():\n",
    "            memory = \"User name is Bob\"\n",
    "            store.put(namespace, str(uuid.uuid4()), {\"data\": memory})\n",
    "\n",
    "        response = model.invoke(\n",
    "            [{\"role\": \"system\", \"content\": system_msg}] + state[\"messages\"]\n",
    "        )\n",
    "        return {\"messages\": response}\n",
    "\n",
    "\n",
    "    builder = StateGraph(MessagesState)\n",
    "    builder.add_node(\"call_model\", call_model)\n",
    "    builder.add_edge(START, \"call_model\")\n",
    " \n",
    "\n",
    "    graph = builder.compile(\n",
    "        checkpointer=checkpointer,\n",
    "        store=store,\n",
    "    )\n",
    "\n",
    "    user_id_name=\"shaktimaan\"\n",
    "    config = {\n",
    "        \"configurable\": {\n",
    "            \"thread_id\": \"2\",\n",
    "            \"user_id\": user_id_name,\n",
    "        }\n",
    "    }\n",
    "    for chunk in graph.stream(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": \"remember: I like Batman not much of superman\"}]},\n",
    "        config,\n",
    "        stream_mode=\"values\",\n",
    "    ):\n",
    "        chunk[\"messages\"][-1].pretty_print()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cba61aa-43ce-47e2-9b2e-83f9403e05af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "614942ba-bd4f-4623-bde2-e261a30bfd95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "remember: And yeah I like Nolan over Russo\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Understood! You prefer Christopher Nolan over the Russo brothers. If you want to discuss anything about films or have more preferences to share, feel free to let me know!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with (\n",
    "    PostgresStore.from_conn_string(DB_URI) as store,\n",
    "    PostgresSaver.from_conn_string(DB_URI) as checkpointer,\n",
    "):\n",
    "    # store.setup()\n",
    "    # checkpointer.setup()\n",
    "\n",
    "    def call_model(\n",
    "        state: MessagesState,\n",
    "        config: RunnableConfig,\n",
    "        *,\n",
    "        store: BaseStore,\n",
    "    ):\n",
    "        user_id = config[\"configurable\"][\"user_id\"]\n",
    "        namespace = (\"memories\", user_id)\n",
    "        memories = store.search(namespace, query=str(state[\"messages\"][-1].content))\n",
    "        info = \"\\n\".join([d.value[\"data\"] for d in memories])\n",
    "        system_msg = f\"You are a helpful assistant talking to the user. User info: {info}\"\n",
    "\n",
    "        # Store new memories if the user asks the model to remember\n",
    "        last_message = state[\"messages\"][-1]\n",
    "        if \"remember\" in last_message.content.lower():\n",
    "            memory = \"User name is Bob\"\n",
    "            store.put(namespace, str(uuid.uuid4()), {\"data\": memory})\n",
    "\n",
    "        response = model.invoke(\n",
    "            [{\"role\": \"system\", \"content\": system_msg}] + state[\"messages\"]\n",
    "        )\n",
    "        return {\"messages\": response}\n",
    "\n",
    "\n",
    "    builder = StateGraph(MessagesState)\n",
    "    builder.add_node(\"call_model\", call_model)\n",
    "    builder.add_edge(START, \"call_model\")\n",
    " \n",
    "\n",
    "    graph = builder.compile(\n",
    "        checkpointer=checkpointer,\n",
    "        store=store,\n",
    "    )\n",
    "\n",
    "    user_id_name=\"shaktimaan\"\n",
    "    config = {\n",
    "        \"configurable\": {\n",
    "            \"thread_id\": \"2\",\n",
    "            \"user_id\": user_id_name,\n",
    "        }\n",
    "    }\n",
    "    for chunk in graph.stream(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": \"remember: And yeah I like Nolan over Russo\"}]},\n",
    "        config,\n",
    "        stream_mode=\"values\",\n",
    "    ):\n",
    "        chunk[\"messages\"][-1].pretty_print()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b312dc50-d28b-4136-bc02-3eeb0978e01f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31b1a9cd-58f5-4b34-8116-2794162a5295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Will you sum up my taste in cinema\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Based on our conversation, your taste in cinema includes:\n",
      "\n",
      "1. **Superheroes**: You prefer Batman over Superman, indicating a liking for more complex and darker narratives within the superhero genre.\n",
      "\n",
      "2. **Directors**: You favor Christopher Nolan over the Russo brothers, suggesting you appreciate films with intricate plots, intellectual depth, and unique visual storytelling.\n",
      "\n",
      "This combination points to a preference for movies that are thought-provoking and have rich, layered storytelling. If there's anything more you'd like to add or discuss, feel free to let me know!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with (\n",
    "    PostgresStore.from_conn_string(DB_URI) as store,\n",
    "    PostgresSaver.from_conn_string(DB_URI) as checkpointer,\n",
    "):\n",
    "    # store.setup()\n",
    "    # checkpointer.setup()\n",
    "\n",
    "    def call_model(\n",
    "        state: MessagesState,\n",
    "        config: RunnableConfig,\n",
    "        *,\n",
    "        store: BaseStore,\n",
    "    ):\n",
    "        user_id = config[\"configurable\"][\"user_id\"]\n",
    "        namespace = (\"memories\", user_id)\n",
    "        memories = store.search(namespace, query=str(state[\"messages\"][-1].content))\n",
    "        info = \"\\n\".join([d.value[\"data\"] for d in memories])\n",
    "        system_msg = f\"You are a helpful assistant talking to the user. User info: {info}\"\n",
    "\n",
    "        # Store new memories if the user asks the model to remember\n",
    "        last_message = state[\"messages\"][-1]\n",
    "        if \"remember\" in last_message.content.lower():\n",
    "            memory = \"User name is Bob\"\n",
    "            store.put(namespace, str(uuid.uuid4()), {\"data\": memory})\n",
    "\n",
    "        response = model.invoke(\n",
    "            [{\"role\": \"system\", \"content\": system_msg}] + state[\"messages\"]\n",
    "        )\n",
    "        return {\"messages\": response}\n",
    "\n",
    "\n",
    "    builder = StateGraph(MessagesState)\n",
    "    builder.add_node(\"call_model\", call_model)\n",
    "    builder.add_edge(START, \"call_model\")\n",
    " \n",
    "\n",
    "    graph = builder.compile(\n",
    "        checkpointer=checkpointer,\n",
    "        store=store,\n",
    "    )\n",
    "\n",
    "    user_id_name=\"shaktimaan\"\n",
    "    config = {\n",
    "        \"configurable\": {\n",
    "            \"thread_id\": \"2\",\n",
    "            \"user_id\": user_id_name,\n",
    "        }\n",
    "    }\n",
    "    for chunk in graph.stream(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": \"Will you sum up my taste in cinema\"}]},\n",
    "        config,\n",
    "        stream_mode=\"values\",\n",
    "    ):\n",
    "        chunk[\"messages\"][-1].pretty_print()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c093c0fa-4e9e-47c4-bcec-fa608b40e28d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b82df87c-f75e-43f7-9efa-38ce6ff2b700",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Divorce' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mDivorce\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'Divorce' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7dbdc98-9847-45a1-af00-a46fb91e50ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74f5cb4-8abc-4cbe-bb54-fdc1cffea47c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
